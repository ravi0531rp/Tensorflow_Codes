{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 as PretrainedModel,preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"D:\\OWN_CODES\\003. Deep Learning\\001. Lazy Prog TF 2\\FoodData\\train\"\n",
    "valid_path = r\"D:\\OWN_CODES\\003. Deep Learning\\001. Lazy Prog TF 2\\FoodData\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [200,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob(train_path + '/*/*.jpg')\n",
    "valid_image_files = glob(valid_path + '/*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob(train_path + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptm = PretrainedModel(\n",
    "        input_shape = IMAGE_SIZE + [3],\n",
    "        weights = 'imagenet',\n",
    "        include_top = False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(ptm.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = ptm.input , outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 200, 200, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 200, 200, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 100, 100, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 100, 100, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 50, 50, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 50, 50, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 25, 25, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 25, 25, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = gen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size = IMAGE_SIZE,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'binary'\n",
    "\n",
    ")\n",
    "\n",
    "test_gen = gen.flow_from_directory(\n",
    "        valid_path,\n",
    "        target_size = IMAGE_SIZE,\n",
    "        batch_size = batch_size,\n",
    "        class_mode = 'binary'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tabular features for computing Z only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = len(image_files)\n",
    "Nvalid = len(valid_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we should figure out the output size of Z stage\n",
    "\n",
    "feat = model.predict(np.random.random([1] + IMAGE_SIZE + [3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18432)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = feat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18432"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((Ntrain,D))\n",
    "y_train = np.zeros(Ntrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.zeros((Nvalid,D))\n",
    "y_valid = np.zeros(Nvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n",
      "896\n",
      "1024\n",
      "1152\n",
      "1280\n",
      "1408\n",
      "1536\n",
      "1664\n",
      "1792\n",
      "1920\n",
      "2048\n",
      "2176\n",
      "2304\n",
      "2432\n",
      "2560\n",
      "2688\n",
      "2816\n",
      "2944\n",
      "3000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "\n",
    "for x,y in train_gen:\n",
    "    features = model.predict(x)\n",
    "    sz = len(y)\n",
    "    \n",
    "    X_train[i:i+sz] = features\n",
    "    y_train[i:i+sz] = y\n",
    "    \n",
    "    i+=sz \n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    if i>= Ntrain:\n",
    "        print(\"Done\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650.8262939453125, 0.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max() , X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "384\n",
      "512\n",
      "640\n",
      "768\n",
      "896\n",
      "1000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "\n",
    "for x,y in test_gen:\n",
    "    features = model.predict(x)\n",
    "    sz = len(y)\n",
    "    \n",
    "    X_valid[i:i+sz] = features\n",
    "    y_valid[i:i+sz] = y\n",
    "    \n",
    "    i+=sz \n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    if i>= Nvalid:\n",
    "        print(\"Done\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train2 = scaler.fit_transform(X_train)\n",
    "X_valid2 = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression()\n",
    "\n",
    "logr.fit(X_train2 , y_train)\n",
    "\n",
    "print(logr.score(X_train2, y_train))\n",
    "print(logr.score(X_valid2, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(D,))\n",
    "x = Dense(1, activation='sigmoid')(i)\n",
    "\n",
    "linearModel = Model(i,x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModel.compile(\n",
    "        loss = 'binary_crossentropy',\n",
    "        optimizer = 'adam',\n",
    "        metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 1s 28ms/step - loss: 1.4084 - accuracy: 0.9100 - val_loss: 0.2787 - val_accuracy: 0.9740\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0724 - accuracy: 0.9923 - val_loss: 0.3087 - val_accuracy: 0.9720\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2860 - val_accuracy: 0.9760\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 5.8070e-04 - accuracy: 0.9997 - val_loss: 0.3444 - val_accuracy: 0.9720\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 3.4953e-05 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9730\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 6.6772e-06 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 5.2443e-06 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9730\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 4.3078e-06 - accuracy: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 3.7932e-06 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9730\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 3.3426e-06 - accuracy: 1.0000 - val_loss: 0.3282 - val_accuracy: 0.9730\n"
     ]
    }
   ],
   "source": [
    "r = linearModel.fit(\n",
    "        X_train,y_train,\n",
    "        batch_size = 128,\n",
    "        epochs = 10,\n",
    "        validation_data = (X_valid,y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16380b93eb8>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY1UlEQVR4nO3df4wc5X3H8ff37mxsftnEPhvjs33GAczZnkvgIISEH0naYOOoqE1a4RSiRIksVKBpWqnQSCSK8leStkqikFgWpShqFNQASWlxoFLaQlJCwrkB24djOPwjPjD4DAZbONi+87d/PLt4b713O3c3e7Mz83lJo92deW7n65Xvs3PPPPOMuTsiIpJ9LWkXICIiyVCgi4jkhAJdRCQnFOgiIjmhQBcRyYm2tHY8d+5c7+zsTGv3IiKZtHnz5gPu3l5rW2qB3tnZSW9vb1q7FxHJJDPbM9o2dbmIiOSEAl1EJCcU6CIiOaFAFxHJCQW6iEhOKNBFRHKibqCb2b1mtt/MttVpd5mZDZvZJ5IrT0RE4opzhH4fsHqsBmbWCnwNeCyBmsa2bRvccQccPtzwXYmIZEndQHf3J4DX6zS7HXgQ2J9EUWPatQu+/nXYurXhuxIRyZJJ96Gb2ULgj4ENMdquN7NeM+sdHByc2A6jKDxu2TKxnxcRyakkTop+E7jD3YfrNXT3je7e4+497e01pyKob/FimDVLgS4iUiWJuVx6gPvNDGAucL2ZDbn7TxJ471OZhaN0BbqIyAiTPkJ396Xu3ununcADwF80LMzLyoGu+6GKiLyj7hG6mf0QuBaYa2YDwJeBaQDuXrffvCGiKIxy2b0bli5NpQQRkWZTN9DdfV3cN3P3T0+qmrgqT4wq0EVEgKxeKbpyZehLVz+6iMg7shnoZ54Jy5Yp0EVEKmQz0EEjXUREqmQ70F94AY4cSbsSEZGmkO1Adw9zu4iISMYDHdTtIiJSkt1AX7o0nBxVoIuIAFkO9JYWWLVKgS4iUpLdQAdNASAiUiH7gX7wILz0UtqViIikLvuBDvDss+nWISLSBLId6KtWhUf1o4uIZDzQZ82Czk4FuogIWQ900BQAIiIl+Qj0HTvg7bfTrkREJFX5CPThYdi+Pe1KRERSlY9AB410EZHCy36gv/vdMHOm+tFFpPCyH+itreEORgp0ESm4uoFuZvea2X4zqzlPrZn9uZltKS1Pmll38mXWEUWhy0VTAIhIgcU5Qr8PWD3G9l3ANe4eAV8FNiZQ1/hEERw4AK++OuW7FhFpFnUD3d2fAF4fY/uT7n6w9PIpoCOh2uLT3OgiIon3oX8W+OloG81svZn1mlnv4OBgcnstTwGgkS4iUmCJBbqZfYgQ6HeM1sbdN7p7j7v3tLe3J7VrmDMHFi7UEbqIFFpbEm9iZhFwD7DG3V9L4j3HrbtbgS4ihTbpI3QzWww8BNzs7s9PvqQJiqJwteixY6mVICKSprpH6Gb2Q+BaYK6ZDQBfBqYBuPsG4EvAHOC7ZgYw5O49jSp4VFEEx4+HeV3KfeoiIgVSN9DdfV2d7Z8DPpdYRRNVOdJFgS4iBZT9K0XLLrwQpk/XSBcRKaz8BPq0abBihU6Mikhh5SfQQTe7EJFCy1+g79sHSV60JCKSEfkLdICtW9OtQ0QkBfkMdHW7iEgB5SvQ582D+fM10kVECilfgQ6aAkBECit/gR5F0NcHQ0NpVyIiMqXyGehHj8ILL6RdiYjIlMpnoIO6XUSkcPIX6MuXQ1ubAl1ECid/gX7aaSHUNdJFRAomf4EOGukiIoWUz0CPIti7Fw4erN9WRCQn8hvooCkARKRQ8h3o6nYRkQLJZ6AvWABz5ijQRaRQ8hnoZuEoXSNdRKRA6ga6md1rZvvNbNso283Mvm1m/Wa2xcwuSb7MCejuhm3bYHg47UpERKZEnCP0+4DVY2xfA1xQWtYD35t8WQmIIjhyBHbuTLsSEZEpUTfQ3f0J4PUxmtwAfN+Dp4DZZrYgqQInTCdGRaRgkuhDXwjsrXg9UFqXrq4uaGlRoItIYSQR6FZjnddsaLbezHrNrHew0ff9nDkTLrxQgS4ihZFEoA8AiypedwAv12ro7hvdvcfde9rb2xPYdR3d3RrpIiKFkUSgPwx8qjTa5QrgTXffl8D7Tl4Uwa5dcOhQ2pWIiDRcW70GZvZD4FpgrpkNAF8GpgG4+wZgE3A90A8cAT7TqGLHrXxidNs2uPLKdGsREWmwuoHu7uvqbHfg1sQqSlLlSBcFuojkXD6vFC1btAhmzdKJUREphHwHuqYAEJECyXegQxjpsnUrnDiRdiUiIg2V/0CPIjh8GPbsSbsSEZGGKkagg/rRRST38h/oK1aEvnQFuojkXP4D/cwzYdkyBbqI5F7+Ax000kVECqEYgd7dDf398NZbaVciItIwxQj0KAJ36OtLuxIRkYYpTqCD+tFFJNeKEeidneHkqAJdRHKsGIHe0gKrVinQRSTXihHocHKki9e8mZKISOYVJ9C7u+GNN2BgIO1KREQaojiBrhOjIpJzxQn0lSvDowJdRHKqOIE+a1YY7aJAF5GcKk6gQ+h2UaCLSE7FCnQzW21mO8ys38zurLF9lpn9u5k9a2Z9ZtY8N4qu1N0NO3bA22+nXYmISOLqBrqZtQJ3A2uALmCdmXVVNbsVeM7du4FrgX8ws+kJ1zp5UQTDw/Dcc2lXIiKSuDhH6JcD/e6+092PAfcDN1S1ceAsMzPgTOB1YCjRSpOgkS4ikmNxAn0hsLfi9UBpXaXvABcDLwNbgc+7e/PdxHPZMpg5U4EuIrkUJ9Ctxrrqyy2vA54BzgPeA3zHzM4+5Y3M1ptZr5n1Dg4OjrvYSWttDcMXFegikkNxAn0AWFTxuoNwJF7pM8BDHvQDu4Dl1W/k7hvdvcfde9rb2yda8+RoCgARyak4gf40cIGZLS2d6LwReLiqze+AjwCY2XzgImBnkoUmprsbDhyAV15JuxIRkUS11Wvg7kNmdhvwGNAK3OvufWZ2S2n7BuCrwH1mtpXQRXOHux9oYN0TV3lidMGCdGsREUlQ3UAHcPdNwKaqdRsqnr8MfDTZ0hpk1arwuGULXHddurWIiCSoWFeKArzrXdDRoROjIpI7xQt00BQAIpJLxQ307dvh2LG0KxERSUwxA727G44fh9/+Nu1KREQSU8xA1xQAIpJDxQz0Cy+E6dMV6CKSK8UM9LY2WLFCgS4iuVLMQAeNdBGR3Cl2oO/bB2lMEiYi0gDFDfTu7vCoo3QRyYniBrpGuohIzhQ30Nvb4dxzFegikhvFDXTQiVERyRUFel8fDDXf7U9FRMar2IHe3Q1Hj8ILL6RdiYjIpBU70MsnRp99Nt06REQSUOxAX748XDWqfnQRyYFiB/r06XDxxQp0EcmFYgc6aKSLiOSGAj2KYO9eOHgw7UpERCYlVqCb2Woz22Fm/WZ25yhtrjWzZ8ysz8weT7bMBipPAbB1a7p1iIhMUt1AN7NW4G5gDdAFrDOzrqo2s4HvAn/k7iuAP21ArY2hkS4ikhNxjtAvB/rdfae7HwPuB26oavNJ4CF3/x2Au+9PtswGOvdcmDtX/egiknlxAn0hsLfi9UBpXaULgXPM7H/MbLOZfarWG5nZejPrNbPewWaZttZMJ0ZFJBfiBLrVWOdVr9uAS4G1wHXAXWZ24Sk/5L7R3Xvcvae9vX3cxTZMFMG2bTA8nHYlIiITFifQB4BFFa87gJdrtHnU3d9y9wPAE0B3MiVOgSiCI0dg5860KxERmbA4gf40cIGZLTWz6cCNwMNVbf4NuMrM2szsdOB9wPZkS20g3exCRHKgbqC7+xBwG/AYIaT/1d37zOwWM7ul1GY78CiwBfg1cI+7b2tc2Qnr6oKWFo10EZFMa4vTyN03AZuq1m2oev0N4BvJlTaFZsyAiy7SEbqIZJquFC3TSBcRyTgFelkUwa5dcOhQ2pWIiEyIAr2sfMXotux0/YuIVFKgl2mki4hknAK9rKMDZs/WSBcRySwFepmmABCRjFOgV4qiMI3uiRNpVyIiMm4K9EpRBIcPw549aVciIjJuCvRK5ZEu6nYRkQxSoFdauTL0pSvQRSSDFOiVzjgD3v1ujXQRkUxSoFfTSBcRySgFerUogv5+eOuttCsRERkXBXq1KAJ36OtLuxIRkXFRoFfTFAAiklEK9GpLlsBZZynQRSRzFOjVWlpg1SqNdBGRzFGg11Ie6eKediUiIrEp0GuJInjjDRgYSLsSEZHYYgW6ma02sx1m1m9md47R7jIzGzazTyRXYgo0BYCIZFDdQDezVuBuYA3QBawzs65R2n0NeCzpIqfcqlXhUYEuIhkS5wj9cqDf3Xe6+zHgfuCGGu1uBx4E9idYXzrOPhuWLtWJURHJlDiBvhDYW/F6oLTuHWa2EPhjYMNYb2Rm682s18x6BwcHx1vr1NIUACKSMXEC3Wqsqx7+8U3gDncfHuuN3H2ju/e4e097e3vcGtMRRbBjB7z9dtqViIjE0hajzQCwqOJ1B/ByVZse4H4zA5gLXG9mQ+7+k0SqTEMUhTsXPfccXHJJ2tWIiNQV5wj9aeACM1tqZtOBG4GHKxu4+1J373T3TuAB4C8yHeagkS4ikjl1j9DdfcjMbiOMXmkF7nX3PjO7pbR9zH7zzFq2DE4/XYEuIpkRp8sFd98EbKpaVzPI3f3Tky+rCbS2hjsYaaSLiGRErEAvrCiCH/84TAFgtc4NS9m+fXDoUPijprzMmKGPTWQqKdDHEkVwzz3wyiuwYEHa1TQNd9i1C5544uTy4ou121YGfHmZObP2+om2nT5dXxwioEAfW+WJ0QIHujts3z4ywF96KWybMweuvhpuvRXmz4cjR05dfv/7U9cdPgyvvnrq+mPHxl9fS8vI8G9rCz1mLS3hsfJ59WMjt7W0hC+a6uejPTZim1n9JW67JJep3ud49ldum0UK9LFUBvp116VbyxQaHg7/5McfD+H985/DgQNh23nnhQC/+mq45hpYvjz8AiS571pfAHG+JMrL0FAYcTo8HJby8+rH8vPjx0ffNtbP1dvmHp67a+LOrEriS6JWu9tvhy9+Mfl6FehjOeccWLQo9yNdjh2DzZtPHn3/4hehPxzg/PPhYx87GeLnn9/Yo5fWVjjzzLDkSTnUK0O+8rHWuvG0qffz9Za47ZJcpnqf49lf0p9bdbvlyxvz/0yBXk8UnTLSxR1eew3efBPmzQs3OMqSI0fgV786GeC//GU44gXo6oJPfjKE91VXQUdHurXmRfnIDMKXlkgjKNBrcA9dDLt3w+5pn2R337PsvmWYPQOtYd1ueOutk+3POAPOPffUZcGCka/nzYNp06b+33PoEPzv/54M8KefDt0MZvCe98D69aH75IMfhGafkUFERmeeUudeT0+P9/b2prJvdxgc5J1w3r0b9uwZ+frIkZE/c87ZQ3Qua6Ozk3eWWbNg//4wCOaVV8LQvfLzgwdP3a8ZzJ0bL/xnz55418aBA6HbpBzgv/lN+JOvrQ0uu+xk98kHPhD+DSKSHWa22d17am3L5RG6ewjasQK73MVQ9q53hZBevhxWrw7PlyyBzuEXWfInlzDr7rvhppti13D0aBjFUR30leH//PPh+dGjp/78aafFC/758+H110eOQOnrC+8xYwa8//1w110hwK+4IowCEZF8ymSgu4ewHC2s9+w5NbDnzAkhffHFsGYNI460lywJU6DXNLQETjs67hOjp50GixeHpd6/5c03ax/ll5edO+HJJ8OR91h/UJ11VjjqvummEOCXXhrqEJFiyFygP/hgCKzqWW3Lgb1iBaxde2pgT/jEZVtbeNMGjXQxC90rs2fXP/N9/HjoKqoM/n37woiQq66C7u5QrogUU+Z+/S+6CG677dTAbugwtyiCRx9t4A7imTYtjAM/77y0KxGRZpS5QF+5Er7xjSneaRTBffeFjvl586Z45yIi8SR4jV+Ola8Y3bo13TpERMagQI9DN7sQkQxQoMfR3h7GCyrQRaSJKdDjiiIFuog0NQV6XFEUrtgZGkq7EhGRmhTocUVRuKTz+efTrkREpKZYgW5mq81sh5n1m9mdNbb/uZltKS1Pmll38qWmTCdGRaTJ1Q10M2sF7gbWAF3AOjPrqmq2C7jG3SPgq8DGpAtN3fLl4coeBbqINKk4R+iXA/3uvtPdjwH3AzdUNnD3J929PL/gU0D+ZtGePj1MBKNAF5EmFSfQFwJ7K14PlNaN5rPAT2ttMLP1ZtZrZr2Dg4Pxq2wWGukiIk0sTqDXmpW75px/ZvYhQqDfUWu7u2909x5372nP4p0Uogj27g3z1YqINJk4gT4ALKp43QG8XN3IzCLgHuAGd38tmfKajKYAEJEmFifQnwYuMLOlZjYduBF4uLKBmS0GHgJudvf8juvTSBcRaWJ1Z1t09yEzuw14DGgF7nX3PjO7pbR9A/AlYA7wXQv3TRsa7RZJmXbuueEecgp0EWlCsabPdfdNwKaqdRsqnn8O+FyypTUhs3AXCQW6iDQhXSk6XlEE27bB8HDalYiIjKBAH68ogiNH4MUX065ERGQEBfp46cSoiDQpBfp4dXVBa6sCXUSajgJ9vGbMCHeqVqCLSJNRoE+EpgAQkSakQJ+IKIJdu+DQobQrERF5hwJ9IjQFgIg0IQX6RGiki4g0IQX6RHR0wOzZCnQRaSoK9InQFAAi0oQU6BMVRfDrX8Of/Rncdx+8+mraFYlIwcWanEtq+MIX4Pe/h02b4Ec/CusuuwzWroXrr4dLL4UWfV+KyNQx95o3H2q4np4e7+3tTWXfiXKHZ56BRx4J4f7UU2Hd/PmwZk0I949+FGbNSrtSEckBM9s82vTkCvSkHTgAjz4aAv6xx+DgQWhrgw9+MIT72rXhZtNW685+IiJjU6CnZWgoHLGXj97LJ1E7O0+G+4c+BDNnplqmiGSHAr1Z7N0bgv2RR+BnPwvT8M6YAR/+cAj3tWthyZK0qxSRJqZAb0Zvvw2PPx7C/ZFHYOfOsL6r62S4X3klTJuWbp0i0lQU6M3OHZ5//mS4P/FE6K6ZNSucUF27NpxgnTcv7UpFJGVjBXqscXVmttrMdphZv5ndWWO7mdm3S9u3mNklky26UMzClLx//dehK+a11+DBB+HjH4ef/xw+/elwg+rLL4evfAV6e+HEibSrFpEmU/cI3cxageeBPwQGgKeBde7+XEWb64HbgeuB9wHfcvf3jfW+OkKP6cSJk8MiH3kkXMxUOSxy7Vp473vDTTfMwtj3lpb6z+NsF5GmM9YRepwLiy4H+t19Z+nN7gduAJ6raHMD8H0P3w5PmdlsM1vg7vsmWbu0tMAll4TlrrtgcPDksMif/CRcpdoo4/mCqPwSqPU41rak2lSvS5vqkNF89rPhL/KExQn0hcDeitcDhKPwem0WAiMC3czWA+sBFi9ePN5aBaC9HW6+OSxDQ/DLX4YTqu7haL78mNTzuG2Hh0N95b/4Kh9rrUu6TfW6tKkOGcv8+Q152ziBXuvrvfp/SZw2uPtGYCOELpcY+5axtLXBVVeFRUQKL85J0QFgUcXrDuDlCbQREZEGihPoTwMXmNlSM5sO3Ag8XNXmYeBTpdEuVwBvqv9cRGRq1e1ycfchM7sNeAxoBe519z4zu6W0fQOwiTDCpR84AnymcSWLiEgtsabPdfdNhNCuXLeh4rkDtyZbmoiIjIcm7BYRyQkFuohITijQRURyQoEuIpITqc22aGaDwJ4J/vhc4ECC5WSdPo+R9HmcpM9ipDx8Hkvcvb3WhtQCfTLMrHe0yWmKSJ/HSPo8TtJnMVLePw91uYiI5IQCXUQkJ7Ia6BvTLqDJ6PMYSZ/HSfosRsr155HJPnQRETlVVo/QRUSkigJdRCQnMhfo9W5YXSRmtsjM/tvMtptZn5l9Pu2a0mZmrWb2GzP7j7RrSVvpVpAPmNlvS/9H3p92TWkxsy+Ufke2mdkPzWxG2jU1QqYCvXTD6ruBNUAXsM7MutKtKlVDwN+4+8XAFcCtBf88AD4PbE+7iCbxLeBRd18OdFPQz8XMFgJ/CfS4+0rCNOA3pltVY2Qq0Km4YbW7HwPKN6wuJHff5+7/V3p+mPALuzDdqtJjZh3AWuCetGtJm5mdDVwN/BOAux9z9zfSrSpVbcBMM2sDTiend1TLWqCPdjPqwjOzTuC9wK/SrSRV3wT+FjiRdiFN4HxgEPjnUhfUPWZ2RtpFpcHdXwL+Hvgd4cb1b7r7f6ZbVWNkLdBj3Yy6aMzsTOBB4K/c/VDa9aTBzD4G7Hf3zWnX0iTagEuA77n7e4G3gEKeczKzcwh/yS8FzgPOMLOb0q2qMbIW6LoZdRUzm0YI8x+4+0Np15OiDwB/ZGa7CV1xHzazf0m3pFQNAAPuXv6L7QFCwBfRHwC73H3Q3Y8DDwFXplxTQ2Qt0OPcsLowzMwIfaTb3f0f064nTe7+d+7e4e6dhP8X/+XuuTwKi8PdXwH2mtlFpVUfAZ5LsaQ0/Q64wsxOL/3OfIScniCOdU/RZjHaDatTLitNHwBuBraa2TOldV8s3QNW5HbgB6WDn50U9Obt7v4rM3sA+D/CyLDfkNMpAHTpv4hITmSty0VEREahQBcRyQkFuohITijQRURyQoEuIpITCnQRkZxQoIuI5MT/A7+scxoRiXAkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'] , color = 'red' , label = 'loss')\n",
    "plt.plot(r.history['val_loss'] , color = 'blue' , label = 'val_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
